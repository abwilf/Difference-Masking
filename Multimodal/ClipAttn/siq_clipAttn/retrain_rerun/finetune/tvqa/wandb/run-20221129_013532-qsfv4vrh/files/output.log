/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../mreserve/checkpoint.py:27: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  return jax.tree_map(_do_cast, tree)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:79: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  running_m = jax.tree_map(_init, params)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:80: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  running_v = jax.tree_map(_init, params)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:126: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  return jax.tree_map(lambda x: (x.ndim > 1) and (x.size > 4096), p)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:27: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  return DecayedWeightsDeltaState(orig_params=jax.tree_map(lambda x: x.astype(jnp.bfloat16), params))
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/flax/jax_utils.py:77: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  return jax.tree_map(lambda x: _replicate(x, devices), tree)
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/jax/_src/lib/xla_bridge.py:528: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.
  warnings.warn(
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/jax/_src/lib/xla_bridge.py:515: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.
  warnings.warn(
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:149: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  state = state.replace(opt_state=jax.tree_map(_shard_opt, state.opt_state))
Now on epoch 0
Resetting iterator, epoch=0, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/dataloader.py:1044: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  item = jax.tree_map(lambda x: x._numpy(), item)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:222: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  init=jax.tree_map(lambda x: jnp.zeros_like(x, dtype=jnp.bfloat16), params),
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/flax/core/scope.py:612: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  abs_value_flat = jax.tree_leaves(abs_value)
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/flax/core/scope.py:613: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  value_flat = jax.tree_leaves(value)
Using dtype <class 'jax.numpy.bfloat16'>
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
Not including audio input
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
adding in audio input!
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
audio2vision x->y dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
audio2vision y->x dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
text2vision x->y dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
text2vision y->x dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:218: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  grads = jax.tree_multimap(lambda a, b: a + b, old_grads, grads)
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/jax/_src/tree_util.py:205: FutureWarning: jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() instead as a drop-in replacement.
  warnings.warn('jax.tree_util.tree_multimap() is deprecated. Please use jax.tree_util.tree_map() '
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:224: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  loss_info = jax.tree_map(lambda x: x.mean(), loss_info)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:228: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  grads = jax.tree_map(lambda x: jnp.nan_to_num(x, copy=False), grads)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:240: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  updates = jax.tree_map(_idx_grad, grads)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:97: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  next_m = jax.tree_multimap(_momentum_update, updates, state.mu)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:98: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  next_m_enc = jax.tree_map(lambda x: x.astype(jnp.bfloat16), next_m)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:100: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  next_v = jax.tree_multimap(_secondorder_update, updates, state.nu)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:101: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  next_v_enc = jax.tree_map(_unsigned_bfloat16_encode, next_v)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:27: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  return jax.tree_map(lambda t: t / bias_correction.astype(t.dtype), moment)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../pretrain/optimization.py:109: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  updates = jax.tree_multimap(
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:30: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  updates = jax.tree_multimap(lambda g, orig_param: g - weight_decay * orig_param.astype(g.dtype),
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/optimization.py:256: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  updates = jax.tree_multimap(_fix_grad, updates, state.params)
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/optax/_src/transform.py:570: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  updates = jax.tree_multimap(
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/optax/_src/transform.py:606: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  updates = jax.tree_map(
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/optax/_src/transform.py:328: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  updates = jax.tree_map(lambda g: step_size * g, updates)
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/optax/_src/update.py:42: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  return jax.tree_multimap(
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/jax/interpreters/mlir.py:583: UserWarning: Some donated buffers were not usable: ShapedArray(bfloat16[1,7,3,60,65]), ShapedArray(int32[1,1,256,2]), ShapedArray(bfloat16[1,7,288,768]), ShapedArray(bfloat16[1,7,288,768]), ShapedArray(bfloat16[1,7,288,768]), ShapedArray(int32[1]), ShapedArray(bfloat16[1]), ShapedArray(int32[1,504]), ShapedArray(int32[1]), ShapedArray(int32[1,1,256,2]), ShapedArray(int32[1,1,760,2]), ShapedArray(int32[1,1,760,2]).
See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.
  warnings.warn(f"Some donated buffers were not usable: {', '.join(unused_donations)}.\n{msg}")
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/tvqa_finetune.py:529: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  train_metrics.append(jax.tree_map(lambda x: x[0], loss_info))
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/tvqa_finetune.py:530: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  jax.tree_map(lambda x: x.copy_to_host_async(), train_metrics[-1])
Using dtype <class 'jax.numpy.bfloat16'>
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
Not including audio input
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
adding in audio input!
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=1/1)>
attention_layer: ~doing attnmask~
audio2vision x->y dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
audio2vision y->x dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
text2vision x->y dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
text2vision y->x dot product sim:  shaped [(504, 768)] -> [(4032, 768)]
Completed 100 batches in 458.923sec, avg 0.218 it/sec
Completed 100 batches in 27.084sec, avg 3.692 it/sec
Completed 100 batches in 27.073sec, avg 3.694 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.100sec, avg 3.690 it/sec
Completed 100 batches in 27.057sec, avg 3.696 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.083sec, avg 3.692 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Now on epoch 1
Resetting iterator, epoch=1, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 2191.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../finetune/common_dataloader.py:465: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  item = jax.tree_map(lambda x: x._numpy(), item)
Using dtype <class 'jax.numpy.bfloat16'>
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((7, 289, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 289, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,289,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
Not including audio input
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((21, 31, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 31, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,31,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~NOT doing attnmask~
Constructing token embs in `prepare_multimodal_inputs`
adding in audio input!
Vision input 6x12: 504. num_pool_segments: 7
Layer 00
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 01
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 02
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 03
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 04
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 05
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 06
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 07
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 08
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 09
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 10
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
Layer 11
Transformer layer my dtype=<class 'jax.numpy.bfloat16'>; x=((2, 760, 768), dtype(bfloat16)); sinusoids=(dtype(bfloat16), (2, 2, 760, 32))
attention_layer: doing rotary: Traced<ShapedArray(bfloat16[2,2,760,32])>with<DynamicJaxprTrace(level=0/1)>
attention_layer: ~doing attnmask~
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/tvqa_finetune.py:505: FutureWarning: jax.tree_multimap is deprecated, and will be removed in a future release. Use jax.tree_util.tree_multimap instead.
  megabatch = jax.tree_multimap(lambda *xs: jnp.concatenate(xs, 1), *outs)
audio2vision x->y dot product sim:  shaped [(4032, 768)] -> [(32256, 768)]
audio2vision y->x dot product sim:  shaped [(4032, 768)] -> [(32256, 768)]
text2vision x->y dot product sim:  shaped [(4032, 768)] -> [(32256, 768)]
text2vision y->x dot product sim:  shaped [(4032, 768)] -> [(32256, 768)]
/home/sakter/anaconda3/envs/mreserve/lib/python3.8/site-packages/jax/interpreters/mlir.py:583: UserWarning: Some donated buffers were not usable: ShapedArray(bfloat16[4032,768]), ShapedArray(bfloat16[4032,768]), ShapedArray(bfloat16[4032,768]), ShapedArray(bfloat16[4032,768]).
See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.
  warnings.warn(f"Some donated buffers were not usable: {', '.join(unused_donations)}.\n{msg}")
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/tvqa_finetune.py:507: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  loss_info = jax.tree_map(lambda x: float(x.mean()), loss_info)
/home/sakter/siq_retrain/retrain_rerun/finetune/tvqa/../../mreserve/checkpoint.py:93: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.
  params = jax.device_get(jax.tree_map(lambda x: x[0], state.params))
Padding final batch by 3
Saving checkpoint at save 2192, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 168.988sec, avg 0.592 it/sec
Completed 100 batches in 19.843sec, avg 5.039 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.255sec, avg 3.669 it/sec
Completed 100 batches in 26.897sec, avg 3.718 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.073sec, avg 3.694 it/sec
Now on epoch 2
Resetting iterator, epoch=2, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 4383.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 4384, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 68.416sec, avg 1.462 it/sec
Completed 100 batches in 21.382sec, avg 4.677 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.082sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Now on epoch 3
Resetting iterator, epoch=3, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 6575.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 6576, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 66.641sec, avg 1.501 it/sec
Completed 100 batches in 22.640sec, avg 4.417 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.083sec, avg 3.692 it/sec
Completed 100 batches in 27.075sec, avg 3.694 it/sec
Completed 100 batches in 27.075sec, avg 3.694 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.604sec, avg 3.623 it/sec
Completed 100 batches in 26.555sec, avg 3.766 it/sec
Completed 100 batches in 27.075sec, avg 3.694 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Now on epoch 4
Resetting iterator, epoch=4, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 8767.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 8768, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 64.983sec, avg 1.539 it/sec
Completed 100 batches in 24.063sec, avg 4.156 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.459sec, avg 3.642 it/sec
Completed 100 batches in 26.694sec, avg 3.746 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.072sec, avg 3.694 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Now on epoch 5
Resetting iterator, epoch=5, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 10959.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 10960, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 62.933sec, avg 1.589 it/sec
Completed 100 batches in 25.735sec, avg 3.886 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.109sec, avg 3.689 it/sec
Completed 100 batches in 27.052sec, avg 3.697 it/sec
Completed 100 batches in 27.238sec, avg 3.671 it/sec
Completed 100 batches in 26.917sec, avg 3.715 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Now on epoch 6
Resetting iterator, epoch=6, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 13151.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Completed 100 batches in 57.912sec, avg 1.727 it/sec
Completed 100 batches in 27.068sec, avg 3.694 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.091sec, avg 3.691 it/sec
Completed 100 batches in 27.063sec, avg 3.695 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.694 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Now on epoch 7
Resetting iterator, epoch=7, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Saving @iter 15343.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Completed 100 batches in 57.935sec, avg 1.726 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.084sec, avg 3.692 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Now on epoch 8
Resetting iterator, epoch=8, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Completed 100 batches in 28.179sec, avg 3.549 it/sec
Saving @iter 17535.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Completed 100 batches in 57.296sec, avg 1.745 it/sec
Completed 100 batches in 27.085sec, avg 3.692 it/sec
Completed 100 batches in 27.072sec, avg 3.694 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.693 it/sec
Completed 100 batches in 27.077sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Now on epoch 9
Resetting iterator, epoch=9, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Completed 100 batches in 27.134sec, avg 3.685 it/sec
Saving @iter 19727.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 19728, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 61.326sec, avg 1.631 it/sec
Completed 100 batches in 27.025sec, avg 3.700 it/sec
Completed 100 batches in 27.076sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.083sec, avg 3.692 it/sec
Completed 100 batches in 27.074sec, avg 3.694 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.081sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.080sec, avg 3.693 it/sec
Completed 100 batches in 27.079sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.693 it/sec
Completed 100 batches in 27.075sec, avg 3.693 it/sec
Completed 100 batches in 27.078sec, avg 3.693 it/sec
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Completed 100 batches in 27.073sec, avg 3.694 it/sec
Now on epoch 10
Resetting iterator, epoch=10, batch of fns=0:64 /64
Constructing TFRecord Input FN over ['/data/siq-less-files/train038of064.tfrecord', '/data/siq-less-files/train050of064.tfrecord', '/data/siq-less-files/train060of064.tfrecord', '/data/siq-less-files/train037of064.tfrecord', '/data/siq-less-files/train000of064.tfrecord', '/data/siq-less-files/train051of064.tfrecord', '/data/siq-less-files/train021of064.tfrecord', '/data/siq-less-files/train027of064.tfrecord', '/data/siq-less-files/train059of064.tfrecord', '/data/siq-less-files/train033of064.tfrecord', '/data/siq-less-files/train022of064.tfrecord', '/data/siq-less-files/train035of064.tfrecord', '/data/siq-less-files/train015of064.tfrecord', '/data/siq-less-files/train034of064.tfrecord', '/data/siq-less-files/train026of064.tfrecord', '/data/siq-less-files/train056of064.tfrecord', '/data/siq-less-files/train044of064.tfrecord', '/data/siq-less-files/train011of064.tfrecord', '/data/siq-less-files/train036of064.tfrecord', '/data/siq-less-files/train062of064.tfrecord', '/data/siq-less-files/train042of064.tfrecord', '/data/siq-less-files/train045of064.tfrecord', '/data/siq-less-files/train061of064.tfrecord', '/data/siq-less-files/train058of064.tfrecord', '/data/siq-less-files/train007of064.tfrecord', '/data/siq-less-files/train009of064.tfrecord', '/data/siq-less-files/train024of064.tfrecord', '/data/siq-less-files/train063of064.tfrecord', '/data/siq-less-files/train016of064.tfrecord', '/data/siq-less-files/train002of064.tfrecord', '/data/siq-less-files/train020of064.tfrecord', '/data/siq-less-files/train055of064.tfrecord', '/data/siq-less-files/train028of064.tfrecord', '/data/siq-less-files/train032of064.tfrecord', '/data/siq-less-files/train029of064.tfrecord', '/data/siq-less-files/train014of064.tfrecord', '/data/siq-less-files/train005of064.tfrecord', '/data/siq-less-files/train054of064.tfrecord', '/data/siq-less-files/train001of064.tfrecord', '/data/siq-less-files/train041of064.tfrecord', '/data/siq-less-files/train003of064.tfrecord', '/data/siq-less-files/train053of064.tfrecord', '/data/siq-less-files/train023of064.tfrecord', '/data/siq-less-files/train057of064.tfrecord', '/data/siq-less-files/train018of064.tfrecord', '/data/siq-less-files/train040of064.tfrecord', '/data/siq-less-files/train017of064.tfrecord', '/data/siq-less-files/train030of064.tfrecord', '/data/siq-less-files/train013of064.tfrecord', '/data/siq-less-files/train052of064.tfrecord', '/data/siq-less-files/train047of064.tfrecord', '/data/siq-less-files/train031of064.tfrecord', '/data/siq-less-files/train010of064.tfrecord', '/data/siq-less-files/train025of064.tfrecord', '/data/siq-less-files/train046of064.tfrecord', '/data/siq-less-files/train039of064.tfrecord', '/data/siq-less-files/train048of064.tfrecord', '/data/siq-less-files/train049of064.tfrecord', '/data/siq-less-files/train012of064.tfrecord', '/data/siq-less-files/train008of064.tfrecord', '/data/siq-less-files/train004of064.tfrecord', '/data/siq-less-files/train006of064.tfrecord', '/data/siq-less-files/train019of064.tfrecord', '/data/siq-less-files/train043of064.tfrecord']
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random resize method:
AREA,BICUBIC,BILINEAR,GAUSSIAN,LANCZOS3,LANCZOS5,MITCHELLCUBIC,NEAREST_NEIGHBOR
Random adjustment of audio clips
Completed 100 batches in 27.082sec, avg 3.692 it/sec
Saving @iter 21919.
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
you passed in random but doing bilinear resize instead (possibly because eager is on)
Padding final batch by 3
Saving checkpoint at save 21920, path /home/sakter/results/retrain_siq/out/base.yaml/tvqa_face_1.0_12_24_0.8_no_proj
Not including the optimizer state
Completed 100 batches in 61.221sec, avg 1.633 it/sec